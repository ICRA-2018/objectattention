{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# objectattention\n",
    "\n",
    "Attending to objects for robot learning.\n",
    "\n",
    "This code provides an interface to the attention mechanism described in \"Deep Object-Centric Representations forGeneralizable Robot Learning\" (Devin et al. 2017) available on arxiv https://arxiv.org/abs/1708.04225. It uses a tensorflow model to attend to objects and it publishes the results to ROS at about 10-20Hz on our machines. This is intended to be used with an robot learning package such as Guided Policy Search  (https://github.com/cbfinn/gps)\n",
    "\n",
    "This code is written for Python2 and Tensorflow 1.2, and ROS Indigo. \n",
    "For dependencies, we recommend using a python virtualenv to avoid conflicts with other pip installs. This is done in the install script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "./setup_linux.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other platforms are not yet supported.\n",
    "\n",
    "\n",
    "To use the example data, copy it into the data directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir taskdata\n",
    "mkdir taskdata/pouring\n",
    "cd taskdata/pouring\n",
    "wget https://people.eecs.berkeley.edu/~coline/data/pouringdata.tar.gz \n",
    "tar -xvf pouringdata.tar.gz\n",
    "rm pouringdata.tar.gz\n",
    "cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will select a crop of the object to initialize the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python get_image_from_demo.py example.yaml\n",
    "python scroll_box.py  taskdata/pouring/myimage.png myfeats.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script will display an image form the demo with the RPN boxes. Click on a pixel to select the box that contains it. If multiple box contains the pixel you clicked, use the left/right arrow keys to cycle through them. Try click on the brown mug and press ENTER when your preferred box is green. This will save out the features to myfeats.npy.\n",
    "\n",
    "If you don't want to do any finetuning, you can just use \"myfeats.npy\" as the attention. However, to finetune follow the following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python process_demo_data.py example.yaml\n",
    "python train_model.py example.yaml -i myfeats.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will save out weights periodically, to reload the network from iteration 10000 and look at it's attention, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python train_model.py example.yaml -t 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will open up an IPython notebook and you can view the soft-attended box by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show(plt.imshow(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To instead save the attention, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python train_model.py example.yaml -s 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which will save it in the experiment directory.\n",
    "\n",
    "Finally, to publish the attention to ros, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python bbox_node.py taskdata/pouring/myexperiment/attention_queries.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acknowledgements:\n",
    "We thank Ronghang Hu for porting RPN from https://github.com/rbgirshick/py-faster-rcnn to tensorflow.\n",
    "This work was done with the support of Huawei Technologies and the National Science Foundation."
   ]
  }
 ],

 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
